{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exterior-break",
   "metadata": {},
   "source": [
    "# Dataset normalization\n",
    "\n",
    "In the sheets of the **dims.xlsx** file there are dictionaries for the data from the **product_prices_cleaned.csv** file. Use `merge` to normalize the data following the steps:\n",
    "\n",
    "1. Read the contents of the **dims.xlsx** file sheets to separate `DataFrames`.\n",
    "For readability base names of frames on the names of sheets.\n",
    "\n",
    "1. Read the data from **product_prices_cleaned.csv** file to the `df` variable.\n",
    "\n",
    "1. Based on the **d_province** workbook, use the `id` column to add the `province_id` column to the `df` frame.\n",
    "\n",
    "1. Based on the  **d_product** workbook, add the `product_id` column to the `df` frame.\n",
    "\n",
    "1. From the table, extract only the columns that refer to other tables, e.g.. **product_id** and the columns **value**, **date**. Do you think this is more readable? What are potential benefits of this approach?\n",
    "\n",
    "> We will tell you how to read many workbooks at once when we discuss `openpyxl`.\n",
    "\n",
    "You can find more about database normalization at the [link](https://www.sqlshack.com/what-is-database-normalization-in-sql-server/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-progressive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
